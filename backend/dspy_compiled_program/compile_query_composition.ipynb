{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianz/miniconda3/envs/ad/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-4o', api_key=os.getenv(\"OPENAI_API_KEY\"), max_tokens=1000)\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Mapping, Any\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    \"\"\"Relationship between two entities extracted from the query\"\"\"\n",
    "\n",
    "    source_entity: str = Field(description=\"Source entity name of the relationship\")\n",
    "    target_entity: str = Field(description=\"Target entity name of the relationship\")\n",
    "    relationship_desc: str = Field(\n",
    "        description=(\n",
    "            \"Description of the relationship, it should be a complete and comprehensive sentence, not few words. \" \n",
    "            \"Sample relationship description: 'TiDB will release a new LTS version every 6 months.'\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class RelationshipReasoning(Relationship):\n",
    "    \"\"\"Relationship between two entities extracted from the query\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=(\n",
    "            \"Category reasoning for the relationship, e.g., 'the main conerns of the user', 'the problem the user is facing', 'the user case scenario', etc.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class DecomposedFactors(BaseModel):\n",
    "    \"\"\"Decomposed factors extracted from the query to form the knowledge graph\"\"\"\n",
    "\n",
    "    relationships: List[RelationshipReasoning] = Field(\n",
    "        description=\"List of relationships to represent critical concepts and their relationships extracted from the query.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class DecomposeQuery(dspy.Signature):\n",
    "    \"\"\"You are a knowledge base graph expert and are very good at building knowledge graphs. Now you are assigned to extract the most critical concepts and their relationships from the query. Step-by-Step Analysis:\n",
    "\n",
    "    1. Extract Meaningful user intents and questions:\n",
    "      - Identify the question what the user itentionally asked, focusing on the the critial information about user's main concerns/questions/problems/use cases, etc.\n",
    "      - Make this question simple and clear and ensure that it is directly related to the user's main concerns. Simple and clear question can improve the search accuracy.\n",
    "    2. Establish Relationships to describe the user's intents:\n",
    "      - Define relationships that accurately represent the user's query intent and information needs.\n",
    "      - Format each relationship as: (Source Entity) - [Relationship] -> (Target Entity), where the relationship describes what the user wants to know about the connection between these entities.\n",
    "\n",
    "    ## Instructions:\n",
    "\n",
    "    - Limit to no more than 3 pairs. These pairs must accurately reflect the user's real (sub)questions.\n",
    "    - Ensure that the extracted pairs are of high quality and do not introduce unnecessary search elements.\n",
    "    - Ensure that the relationships and intents are grounded and factual, based on the information provided in the query.\n",
    "    \"\"\"\n",
    "\n",
    "    query: str = dspy.InputField(\n",
    "        desc=\"The query text to extract the most critical concepts and their relationships from the query.\"\n",
    "    )\n",
    "    factors: DecomposedFactors = dspy.OutputField(\n",
    "        desc=\"Factors representation of the critical concepts and their relationships extracted from the query.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.functional import TypedPredictor\n",
    "\n",
    "class DecomposeQueryModule(dspy.Module):\n",
    "    def __init__(self, dspy_lm: dspy.LM):\n",
    "        super().__init__()\n",
    "        self.dspy_lm = dspy_lm\n",
    "        self.prog = TypedPredictor(DecomposeQuery)\n",
    "\n",
    "    def forward(self, query):\n",
    "        with dspy.settings.context(lm=self.dspy_lm):\n",
    "            return self.prog(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "Query: Chat2query is returning an error message saying \"Query timeout expired\". Additionally, I am unable to locate this SQL query in the slow query log.\n",
      "############################################################\n",
      "Source Entity: Chat2query\n",
      "Target Entity: Error Message\n",
      "Relationship Description: Chat2query is returning an error message saying 'Query timeout expired'.\n",
      "Reasoning: The main problem the user is facing.\n",
      "------------------------------------------------------------\n",
      "Source Entity: SQL Query\n",
      "Target Entity: Slow Query Log\n",
      "Relationship Description: The reason why not to locate the SQL query in the slow query log.\n",
      "Reasoning: The secondary problem the user is facing.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: Hi, how do u setup tidb on debian vps?\n",
      "############################################################\n",
      "Source Entity: TiDB Cluster\n",
      "Target Entity: Debian VPS\n",
      "Relationship Description: How to deploy a TiDB Cluster on a Debian VPS? Should I use TiUP or TiDB Operator?\n",
      "Reasoning: The main question the user is asking.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: I am current using tidb serverless, but as my product grows, I really need a dalicated cluster. Is there a solution helps finish the migration?\n",
      "############################################################\n",
      "Source Entity: TiDB Serverless\n",
      "Target Entity: Dedicated Cluster\n",
      "Relationship Description: How to migrate from TiDB serverless to TiDB dedicated cluster?\n",
      "Reasoning: The main concern of the user.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: I am designing a table based on TiDB's TTL feature, but when I try to create the table using a cluster created with Serverless, I get a `'TTL' is not supported on TiDB Serverless` error.\n",
      "\n",
      "I plan to use Dedicated on my production environment and Serverless on my development environment, so it would be helpful if the TTL feature could be used in a Serverless environment.\n",
      "\n",
      "I've read the documentation that says Serverless will support TTL features in the future, but is there a specific timeline for this?\n",
      "\n",
      "Also, is it possible to prevent TTL syntax from causing errors in Serverless?\n",
      "############################################################\n",
      "Source Entity: TTL Feature\n",
      "Target Entity: TiDB Serverless\n",
      "Relationship Description: The TTL feature is not currently supported in TiDB Serverless.\n",
      "Reasoning: The problem the user is facing.\n",
      "------------------------------------------------------------\n",
      "Source Entity: TTL Feature\n",
      "Target Entity: Roadmap Support Timeline\n",
      "Relationship Description: What's the roadmap timeline on when the TTL feature will be supported in TiDB Serverless.\n",
      "Reasoning: The main question the user is asking.\n",
      "------------------------------------------------------------\n",
      "Source Entity: TTL SQL Syntax\n",
      "Target Entity: Workaround for SQL Syntax Error\n",
      "Relationship Description: Workaround to prevent TTL feature SQL syntax from causing errors in TiDB Serverless.\n",
      "Reasoning: The secondary question the user is asking.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: I'm attempting to download a specific backup from the database hosted on TiDB Cloud. So far, I've tried accessing the backup through SQL queries, but haven't found a way to execute this operation.\n",
      "\n",
      "The instructions provided suggested using SSH to transfer the backup, however, I don't have SSH access to the server where the backups are stored.\n",
      "\n",
      "I would like to request guidance on how I can proceed to download this backup without direct access to the server. Is there an alternative or different method that I can use to obtain the desired backup?\n",
      "\n",
      "Thank you in advance for any assistance or guidance you can provide on this matter.\n",
      "############################################################\n",
      "Source Entity: Backup data\n",
      "Target Entity: TiDB Cloud\n",
      "Relationship Description: How to download a specific backup from TiDB Cloud?\n",
      "Reasoning: The main question the user is asking\n",
      "------------------------------------------------------------\n",
      "Source Entity: Backup SQL\n",
      "Target Entity: Backup data\n",
      "Relationship Description: I can't find a way to execute Backup SQL queries to download the backup.\n",
      "Reasoning: The problem the user is facing\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: Please speak Chinese\n",
      "############################################################\n",
      "Source Entity: User\n",
      "Target Entity: Language\n",
      "Relationship Description: The user is requesting to communicate in Chinese.\n",
      "Reasoning: the main concern of the user\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: Upgrade TiDB Serverless to 7.4 or latest for enhanced MySQL 8.0 compatibility\n",
      "############################################################\n",
      "Source Entity: TiDB 7.4 or Latest version\n",
      "Target Entity: MySQL 8.0 Compatibility\n",
      "Relationship Description: TiDB 7.4 or the latest version enhances compatibility with MySQL 8.0\n",
      "Reasoning: The reasoning why user wants to upgrade TiDB Serverless to 7.4 or latest for enhanced MySQL 8.0 compatibility\n",
      "------------------------------------------------------------\n",
      "Source Entity: TiDB Serverless\n",
      "Target Entity: Upgrade\n",
      "Relationship Description: How to upgrade TiDB Serverless?\n",
      "Reasoning: The basic question what the user itentionally asked.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: We are new to TiDB and don't quite understand the potential impact on our application architecture. We are using TiDB for audit logs and continue to direct traffic to TiDB. We noticed a sudden jump ID from 1 to 30,001. Are there any impacts? Do we need to address this? If we have 100 connections from several applications, what will happen? In summary, what should we do for Auto Increment or do nothing?\n",
      "############################################################\n",
      "Source Entity: Auto Increment\n",
      "Target Entity: ID Jump\n",
      "Relationship Description: Why Auto Increment in TiDB causes a sudden increase in the ID values?\n",
      "Reasoning: The main concerns that the user itentionally asked.\n",
      "------------------------------------------------------------\n",
      "Source Entity: Connections Impact\n",
      "Target Entity: TiDB\n",
      "Relationship Description: How 100 connections from several applications affect TiDB, especially when the Auto Increment causes a sudden jump in ID values?\n",
      "Reasoning: The second most important question that the user itentionally asked.\n",
      "------------------------------------------------------------\n",
      "Source Entity: TiDB\n",
      "Target Entity: Audit Logs\n",
      "Relationship Description: TiDB is used for storing audit logs and receiving continuous traffic.\n",
      "Reasoning: The user case what the user wants to achieve\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: my cluster shows \"available\" but my app containers can no longer reach the database\n",
      "############################################################\n",
      "Source Entity: App Containers\n",
      "Target Entity: TiDB Database\n",
      "Relationship Description: How to solve the connection issue between the app containers and the TiDB database?\n",
      "Reasoning: The main problem the user is facing.\n",
      "------------------------------------------------------------\n",
      "Source Entity: Connectivity Issue\n",
      "Target Entity: Cluster Status\n",
      "Relationship Description: The connectivity issue exists despite the cluster status showing 'available'.\n",
      "Reasoning: The discrepancy the user is concerned about.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "############################################################\n",
      "Query: tidb lighting to sync to serverless cluster,but the load command and the tidb-lighting tools dont have the tls config like --ssl-ca or --ca. so i can not sync to the full back data to the serverless\n",
      "############################################################\n",
      "Source Entity: TiDB Lighting\n",
      "Target Entity: Serverless Cluster\n",
      "Relationship Description: Sync data to a serverless cluster using TiDB Lighting.\n",
      "Reasoning: The user case what the user wants to achieve\n",
      "------------------------------------------------------------\n",
      "Source Entity: Load Command and TiDB Lighting Tools\n",
      "Target Entity: TLS Configuration\n",
      "Relationship Description: How to configure TLS for TiDB Lightning?\n",
      "Reasoning: The basic question what the user itentionally asked.\n",
      "------------------------------------------------------------\n",
      "Source Entity: Lack of TLS Configuration\n",
      "Target Entity: Sync Issue\n",
      "Relationship Description: The sync issue is caused by the lack of TLS configuration options for TiDB Lightning.\n",
      "Reasoning: The problem that the user is facing.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "decompose_query_samples = []\n",
    "\n",
    "dataset_relationships_path = 'data/decompose_query_samples.json'\n",
    "\n",
    "# if file exists\n",
    "if os.path.exists(dataset_relationships_path):\n",
    "    # Load the dataset from the file\n",
    "    # columns = [source_entity, relationship_desc, target_entity, query]\n",
    "    relationship_df = pd.read_json(dataset_relationships_path)\n",
    "    # Group the relationships by query\n",
    "    grouped = relationship_df.groupby('query', group_keys=False)\n",
    "    decompose_query_samples = []\n",
    "    for query, group in grouped:\n",
    "        relationships = [\n",
    "            RelationshipReasoning(\n",
    "                source_entity=row['source_entity'],\n",
    "                relationship_desc=row['relationship_desc'],\n",
    "                target_entity=row['target_entity'],\n",
    "                reasoning=row['reasoning']\n",
    "            )\n",
    "            for _, row in group.iterrows()\n",
    "        ]\n",
    "        decompose_query_instance = DecomposeQuery(query=query, factors=DecomposedFactors(relationships=relationships))\n",
    "        decompose_query_samples.append(decompose_query_instance)\n",
    "\n",
    "for sample in decompose_query_samples:\n",
    "    print(\"#\"*60)\n",
    "    print(f\"Query: {sample.query}\")\n",
    "    print(\"#\"*60)\n",
    "    for relationship in sample.factors.relationships:\n",
    "        print(f\"Source Entity: {relationship.source_entity}\")\n",
    "        print(f\"Target Entity: {relationship.target_entity}\")\n",
    "        print(f\"Relationship Description: {relationship.relationship_desc}\")\n",
    "        print(f\"Reasoning: {relationship.reasoning}\")\n",
    "        print(\"-\"*60)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = [\n",
    "    dspy.Example(\n",
    "        query=sample.query,\n",
    "        factors=sample.factors\n",
    "    ) for sample in decompose_query_samples\n",
    "]\n",
    "trainset = [x.with_inputs('query') for x in dataset]\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:29,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:18,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:08<00:21,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:14<00:24,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:19<00:21,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:20<00:13,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:24<00:10,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:31<00:09,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:35<00:04,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.functional import TypedChainOfThought, TypedPredictor\n",
    "import traceback\n",
    "\n",
    "class AssessmentReuslt(BaseModel):\n",
    "    \"\"\"The assessment result of the entities and relationships\"\"\"\n",
    "\n",
    "    score: float = Field(\n",
    "        description=\"float between 0 and 1 indicating the quality of the graph extraction, 1 being the best, 0 being the worst\"\n",
    "    )\n",
    "   \n",
    "class RelationshipsAssess(dspy.Signature):\n",
    "    \"\"\"Based on the golden relationships, assess the quality of the assessed relationships.\n",
    "To conduct a thorough quality assessment using golden relationships as the benchmark, consider the following evaluation points each counted as 25% of the total score:\n",
    "1. Correctness of Relationship;\n",
    "2. Criticality of Relationship;\n",
    "3. Completeness of Relationship;\n",
    "4. Richness of Relationship Descriptions.\"\"\"\n",
    "\n",
    "    assessed_relationships: list[Relationship] = dspy.InputField(desc=\"the relationships waited to be assessed\")\n",
    "    gold_relationships: list[Relationship] = dspy.InputField(desc=\"the gold relationships\")\n",
    "    result:AssessmentReuslt = dspy.OutputField(desc=\"the assessment result\")\n",
    "\n",
    "def assessment_metric(gold, pred, trace=None):\n",
    "    with dspy.context(lm=turbo):\n",
    "        try:\n",
    "            relationship_score = TypedPredictor(RelationshipsAssess)(\n",
    "                assessed_relationships=pred.factors.relationships,\n",
    "                gold_relationships=gold.factors.relationships,\n",
    "                config={\n",
    "                    \"response_format\":{ \"type\": \"json_object\" },\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "        \n",
    "    print(f\"Relationship score: {relationship_score.result.score}\")\n",
    "\n",
    "    if trace is None: # if we're doing evaluation or optimization\n",
    "        #return relationship_score.result.score >= 0.85\n",
    "        pass\n",
    "\n",
    "    return relationship_score.result.score >= 0.85\n",
    "\n",
    "\n",
    "teleprompter = BootstrapFewShot(metric=assessment_metric)\n",
    "\n",
    "# Compile!\n",
    "compiled_dp_program = teleprompter.compile(DecomposeQueryModule(turbo), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_dp_program.save(\"data/decompose_query_program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"请说中文\"\"\"\n",
    "executor = DecomposeQueryModule(turbo)\n",
    "executor.load(\"data/decompose_query_program\")\n",
    "pred = executor(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 请说中文\n",
      "\n",
      "############# decomposed queries ###################\n",
      "User -> The user is requesting to communicate in Chinese. -> Language\n",
      "reasoning: The main concern of the user.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "\n",
    "print(f\"\\n############# decomposed queries ###################\")\n",
    "for relationship in pred.factors.relationships:\n",
    "    print(f\"{relationship.source_entity} -> {relationship.relationship_desc} -> {relationship.target_entity}\")\n",
    "    print(f\"reasoning: {relationship.reasoning}\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.factors.relationships[1].relationship_desc = \"The reason why not to locate the SQL query in the slow query log.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo.inspect_history(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from decompose_query_samples to df, and save into json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "decompose_query_samples_df = pd.DataFrame(columns=['query', 'source_entity', 'target_entity', 'relationship_desc'])\n",
    "\n",
    "decompose_query_samples.append(DecomposeQuery(query=query, factors=pred.factors))\n",
    "\n",
    "for sample in decompose_query_samples:\n",
    "    query = sample.query\n",
    "    for relationship in sample.factors.relationships:\n",
    "        decompose_query_samples_df = pd.concat([\n",
    "            decompose_query_samples_df, \n",
    "            pd.DataFrame(\n",
    "                [[query, relationship.source_entity, relationship.target_entity, relationship.relationship_desc, relationship.reasoning]], \n",
    "                columns=['query', 'source_entity', 'target_entity', 'relationship_desc', \"reasoning\"]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "decompose_query_samples_df.to_json('data/decompose_query_samples.json', orient='records', indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
